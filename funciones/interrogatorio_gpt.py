import streamlit as st
import openai

def interrogatorio_gpt(datos_paciente, openai_client, modelo):
    st.header("Interrogatorio M√©dico con GPT")

    # Cargar el prompt (NO se env√≠a a GPT en la conversaci√≥n)
    with open('gpt_config/prompt.txt', 'r') as file:
        prompt = file.read()

    # Contenedor para el chat
    chat_container = st.container()

    # Inicializar la conversaci√≥n con la pregunta inicial de GPT
    if "conversation" not in st.session_state:
        prompt_inicial = f"{prompt}\nDatos del paciente:\nEdad: {datos_paciente['edad']} a√±os\nPeso: {datos_paciente['peso']} kg\nTalla: {datos_paciente['talla']} cm\n\nHola, ¬øpodr√≠as contarme cu√°les son tus s√≠ntomas?" 
        st.session_state.conversation = [{"role": "system", "content": prompt_inicial}]
        
    # Manejar la conversaci√≥n (similar a como lo hac√≠as antes)
    if st.session_state.get("conversation"):
        with chat_container:
            for message in st.session_state.conversation:
                if message["role"] == "user":
                    st.write("üë§ Usuario:", message["content"])
                else:
                    st.write("ü§ñ GPT:", message["content"])

        # Input del usuario
        user_input = st.text_area("T√∫:", key="user_input")
        if user_input:
            st.session_state.conversation.append({"role": "user", "content": user_input})
            
            # Obtener la respuesta de GPT
            response = openai_client.chat.completions.create(
                model=modelo,
                messages=st.session_state.conversation
            )
            message = response.choices[0].message.content 
            st.session_state.conversation.append({"role": "assistant", "content": message})

            # Mostrar el nuevo mensaje de GPT
            with chat_container:
                st.write("ü§ñ GPT:", message) 

    # (Opcional) Devolver toda la conversaci√≥n para su posterior procesamiento
    return st.session_state.conversation 
