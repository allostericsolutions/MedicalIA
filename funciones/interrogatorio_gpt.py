import streamlit as st
import openai

def interrogatorio_gpt(datos_paciente, openai_client, modelo):
    # ... (resto del cÃ³digo)

    # Inicializar la conversaciÃ³n con la pregunta inicial de GPT
    if "conversation" not in st.session_state:
        prompt_inicial = f"{prompt}\nDatos del paciente:\nEdad: {datos_paciente['edad']} aÃ±os\nPeso: {datos_paciente['peso']} kg\nAltura: {datos_paciente['altura']} cm\n\nHola, Â¿podrÃ­as contarme cuÃ¡les son tus sÃ­ntomas?" 
        st.session_state.conversation = [{"role": "system", "content": prompt_inicial}]
        
    # Manejar la conversaciÃ³n (similar a como lo hacÃ­as antes)
    if st.session_state.get("conversation"):
        with chat_container:
            for message in st.session_state.conversation:
                if message["role"] == "user":
                    st.write("ğŸ‘¤ Usuario:", message["content"])
                else:
                    st.write("ğŸ¤– GPT:", message["content"])

        # Input del usuario
        user_input = st.text_area("TÃº:", key="user_input")
        if user_input:
            st.session_state.conversation.append({"role": "user", "content": user_input})
            
            # Obtener la respuesta de GPT
            response = openai_client.chat.completions.create(
                model=modelo,
                messages=st.session_state.conversation
            )
            message = response.choices[0].message.content 
            st.session_state.conversation.append({"role": "assistant", "content": message})

            # Mostrar el nuevo mensaje de GPT
            with chat_container:
                st.write("ğŸ¤– GPT:", message) 

    # (Opcional) Devolver toda la conversaciÃ³n para su posterior procesamiento
    return st.session_state.conversation 
